{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(r\"Restaurant_Reviews.tsv\",delimiter ='\\t',quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = features.rename(columns = {\"Review\":\"description\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preprocessing\n",
    "\n",
    "#Removing Stopwords and punctuation\n",
    "\n",
    "sw = set(stopwords.words('english'))-set(['not'])\n",
    "def remove_pun_stopwords(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = [i.lower() for i in text.lower().split() if i not in sw]\n",
    "    return(' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['description'] = features['description'].apply(remove_pun_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = features[features['Liked'] == 0]\n",
    "positive = features[features['Liked'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Average lenth of positive reviews\n",
    "negative['len_of_words'] = negative['description'].apply(lambda x : len(x))\n",
    "\n",
    "###Average lenth of negative reviews\n",
    "positive['len_of_words'] = positive['description'].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding frequency of words in positive and negative reviews \n",
    "freq_n = pd.Series((' '.join(negative['description']).split())).value_counts()\n",
    "freq_p = pd.Series((' '.join(positive['description']).split())).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_positive_review_wrds = list(freq_p.head(5).index)\n",
    "top_negative_review_wrds = list(freq_n.head(5).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_word_count(text):\n",
    "    x = 0\n",
    "    for i in text.split():\n",
    "        for j in top_positive_review_wrds:\n",
    "            y = i.count(j)\n",
    "            x+=y\n",
    "    return(x)\n",
    "def negative_word_count(text):\n",
    "    x = 0\n",
    "    for i in text.split():\n",
    "        for j in top_negative_review_wrds:\n",
    "            y = i.count(j)\n",
    "            x+=y\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "###taking count of positive and negative word in each review\n",
    "features['good_words_count'] = features['description'].apply(positive_word_count)\n",
    "features['bad_word_count'] = features['description'].apply(negative_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['len_of_words'] = features['description'].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Stemming the words\n",
    "ps = SnowballStemmer('english')\n",
    "def stem_words(text):\n",
    "    text = [ps.stem(i) for i in text.split()]\n",
    "    return(' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['description'] = features['description'].apply(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>Liked</th>\n",
       "      <th>good_words_count</th>\n",
       "      <th>bad_word_count</th>\n",
       "      <th>len_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wow love place</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crust not good</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not tasti textur nasti</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stop late may bank holiday rick steve recommen...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>select menu great price</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  Liked  good_words_count  \\\n",
       "0                                     wow love place      1                 1   \n",
       "1                                     crust not good      0                 1   \n",
       "2                             not tasti textur nasti      0                 0   \n",
       "3  stop late may bank holiday rick steve recommen...      1                 0   \n",
       "4                            select menu great price      1                 1   \n",
       "\n",
       "   bad_word_count  len_of_words  \n",
       "0               1            15  \n",
       "1               1            14  \n",
       "2               1            23  \n",
       "3               0            61  \n",
       "4               0            27  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "### Converting the text in count vector\n",
    "X = cv.fit_transform(features['description']).toarray()\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging Count vector with the features we created above\n",
    "X = pd.concat([X,features.iloc[:,2:5]],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1608</th>\n",
       "      <th>1609</th>\n",
       "      <th>1610</th>\n",
       "      <th>1611</th>\n",
       "      <th>1612</th>\n",
       "      <th>1613</th>\n",
       "      <th>1614</th>\n",
       "      <th>good_words_count</th>\n",
       "      <th>bad_word_count</th>\n",
       "      <th>len_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1618 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  1608  1609  1610  1611  1612  1613  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "\n",
       "   1614  good_words_count  bad_word_count  len_of_words  \n",
       "0     0                 1               1            15  \n",
       "1     0                 1               1            14  \n",
       "2     0                 0               1            23  \n",
       "3     0                 0               0            61  \n",
       "4     0                 1               0            27  \n",
       "\n",
       "[5 rows x 1618 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = features['Liked']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We will do prediction using various algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.715\n",
      "Precision Score : 0.896551724137931\n",
      "Recall Score : 0.5048543689320388\n",
      "F1 Score : 0.6459627329192547\n"
     ]
    }
   ],
   "source": [
    "## Algo_1 = XG Boost\n",
    "\n",
    "classifier1 = xgb.XGBClassifier(n_estimators=100)\n",
    "classifier1.fit(X_train, y_train)\n",
    "\n",
    "y_pred_1 = classifier1.predict(X_test)\n",
    "\n",
    "cm_1 = confusion_matrix(y_test, y_pred_1)\n",
    "\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_1)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_1)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_1)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.82\n",
      "Precision Score : 0.8383838383838383\n",
      "Recall Score : 0.8058252427184466\n",
      "F1 Score : 0.8217821782178217\n"
     ]
    }
   ],
   "source": [
    "## Algo_1 = Random Forest\n",
    "\n",
    "classifier2 = RandomForestClassifier(n_estimators=300)\n",
    "classifier2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_2 = classifier2.predict(X_test)\n",
    "\n",
    "cm_2 = confusion_matrix(y_test, y_pred_2)\n",
    "\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_2)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_2)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_2)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 80 samples\n",
      "Epoch 1/20\n",
      "720/720 [==============================] - 0s 492us/sample - loss: 0.6891 - accuracy: 0.5236 - val_loss: 0.6908 - val_accuracy: 0.5250\n",
      "Epoch 2/20\n",
      "720/720 [==============================] - 0s 212us/sample - loss: 0.6836 - accuracy: 0.5458 - val_loss: 0.6525 - val_accuracy: 0.7000\n",
      "Epoch 3/20\n",
      "720/720 [==============================] - 0s 208us/sample - loss: 0.6251 - accuracy: 0.7292 - val_loss: 0.6486 - val_accuracy: 0.5125\n",
      "Epoch 4/20\n",
      "720/720 [==============================] - 0s 204us/sample - loss: 0.5216 - accuracy: 0.8056 - val_loss: 0.5392 - val_accuracy: 0.7125\n",
      "Epoch 5/20\n",
      "720/720 [==============================] - 0s 206us/sample - loss: 0.3900 - accuracy: 0.8986 - val_loss: 0.4182 - val_accuracy: 0.8625\n",
      "Epoch 6/20\n",
      "720/720 [==============================] - 0s 195us/sample - loss: 0.2742 - accuracy: 0.9361 - val_loss: 0.4326 - val_accuracy: 0.8250\n",
      "Epoch 7/20\n",
      "720/720 [==============================] - 0s 197us/sample - loss: 0.2108 - accuracy: 0.9417 - val_loss: 0.3815 - val_accuracy: 0.8250\n",
      "Epoch 8/20\n",
      "720/720 [==============================] - 0s 197us/sample - loss: 0.1510 - accuracy: 0.9708 - val_loss: 0.3501 - val_accuracy: 0.8500\n",
      "Epoch 9/20\n",
      "720/720 [==============================] - 0s 194us/sample - loss: 0.1237 - accuracy: 0.9722 - val_loss: 0.3765 - val_accuracy: 0.8125\n",
      "Epoch 10/20\n",
      "720/720 [==============================] - 0s 195us/sample - loss: 0.0957 - accuracy: 0.9819 - val_loss: 0.4832 - val_accuracy: 0.7875\n",
      "Epoch 11/20\n",
      "720/720 [==============================] - 0s 206us/sample - loss: 0.0746 - accuracy: 0.9875 - val_loss: 0.3954 - val_accuracy: 0.8250\n",
      "Epoch 12/20\n",
      "720/720 [==============================] - 0s 197us/sample - loss: 0.0624 - accuracy: 0.9875 - val_loss: 0.4739 - val_accuracy: 0.7750\n",
      "Epoch 13/20\n",
      "720/720 [==============================] - 0s 201us/sample - loss: 0.0535 - accuracy: 0.9903 - val_loss: 0.4988 - val_accuracy: 0.7875\n",
      "Epoch 14/20\n",
      "720/720 [==============================] - 0s 198us/sample - loss: 0.0458 - accuracy: 0.9903 - val_loss: 0.4485 - val_accuracy: 0.7875\n",
      "Epoch 15/20\n",
      "720/720 [==============================] - 0s 197us/sample - loss: 0.0393 - accuracy: 0.9903 - val_loss: 0.5318 - val_accuracy: 0.7625\n",
      "Epoch 16/20\n",
      "720/720 [==============================] - 0s 197us/sample - loss: 0.0349 - accuracy: 0.9958 - val_loss: 0.4938 - val_accuracy: 0.7875\n",
      "Epoch 17/20\n",
      "720/720 [==============================] - 0s 204us/sample - loss: 0.0329 - accuracy: 0.9931 - val_loss: 0.4961 - val_accuracy: 0.8125\n",
      "Epoch 18/20\n",
      "720/720 [==============================] - 0s 213us/sample - loss: 0.0287 - accuracy: 0.9931 - val_loss: 0.5145 - val_accuracy: 0.7875\n",
      "Epoch 19/20\n",
      "720/720 [==============================] - 0s 195us/sample - loss: 0.0270 - accuracy: 0.9944 - val_loss: 0.5553 - val_accuracy: 0.7875\n",
      "Epoch 20/20\n",
      "720/720 [==============================] - 0s 195us/sample - loss: 0.0243 - accuracy: 0.9972 - val_loss: 0.5679 - val_accuracy: 0.7750\n"
     ]
    }
   ],
   "source": [
    "## Algo_3 = ANN\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 100,activation = 'sigmoid',input_shape = (X_train.shape[1],)))\n",
    "\n",
    "classifier.add(Dense(units = 100,activation = 'sigmoid'))\n",
    "\n",
    "classifier.add(Dense(units = 1,activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "classifier.compile(loss= 'binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs= 20,validation_split = 0.1)\n",
    "\n",
    "y_pred_3 = classifier.predict(X_test)\n",
    "\n",
    "y_pred_3 = [1 if i>0.5 else 0 for i in y_pred_3 ]\n",
    "\n",
    "cm_3 = confusion_matrix(y_test,y_pred_3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.835\n",
      "Precision Score : 0.8240740740740741\n",
      "Recall Score : 0.8640776699029126\n",
      "F1 Score : 0.8436018957345971\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_3)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_3)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_3)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Same operation using the TFID Vector\n",
    "\n",
    "cv = TfidfVectorizer()\n",
    "### Converting the text in count vector\n",
    "X = cv.fit_transform(features['description']).toarray()\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging Count vector with the features we created above\n",
    "X = pd.concat([X,features.iloc[:,2:5]],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1608</th>\n",
       "      <th>1609</th>\n",
       "      <th>1610</th>\n",
       "      <th>1611</th>\n",
       "      <th>1612</th>\n",
       "      <th>1613</th>\n",
       "      <th>1614</th>\n",
       "      <th>good_words_count</th>\n",
       "      <th>bad_word_count</th>\n",
       "      <th>len_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1618 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  1608  1609  1610  1611  1612  1613  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "\n",
       "   1614  good_words_count  bad_word_count  len_of_words  \n",
       "0     0                 1               1            15  \n",
       "1     0                 1               1            14  \n",
       "2     0                 0               1            23  \n",
       "3     0                 0               0            61  \n",
       "4     0                 1               0            27  \n",
       "\n",
       "[5 rows x 1618 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = features['Liked']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We will do prediction using various algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.715\n",
      "Precision Score : 0.896551724137931\n",
      "Recall Score : 0.5048543689320388\n",
      "F1 Score : 0.6459627329192547\n"
     ]
    }
   ],
   "source": [
    "## Algo_1 = XG Boost\n",
    "\n",
    "classifier1 = xgb.XGBClassifier(n_estimators=100)\n",
    "classifier1.fit(X_train, y_train)\n",
    "\n",
    "y_pred_1 = classifier1.predict(X_test)\n",
    "\n",
    "cm_1 = confusion_matrix(y_test, y_pred_1)\n",
    "\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_1)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_1)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_1)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.82\n",
      "Precision Score : 0.8383838383838383\n",
      "Recall Score : 0.8058252427184466\n",
      "F1 Score : 0.8217821782178217\n"
     ]
    }
   ],
   "source": [
    "## Algo_1 = Random Forest\n",
    "\n",
    "classifier2 = RandomForestClassifier(n_estimators=300)\n",
    "classifier2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_2 = classifier2.predict(X_test)\n",
    "\n",
    "cm_2 = confusion_matrix(y_test, y_pred_2)\n",
    "\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_2)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_2)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_2)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 80 samples\n",
      "Epoch 1/20\n",
      "720/720 [==============================] - 0s 492us/sample - loss: 0.6891 - accuracy: 0.5236 - val_loss: 0.6908 - val_accuracy: 0.5250\n",
      "Epoch 2/20\n",
      "720/720 [==============================] - 0s 212us/sample - loss: 0.6836 - accuracy: 0.5458 - val_loss: 0.6525 - val_accuracy: 0.7000\n",
      "Epoch 3/20\n",
      "720/720 [==============================] - 0s 208us/sample - loss: 0.6251 - accuracy: 0.7292 - val_loss: 0.6486 - val_accuracy: 0.5125\n",
      "Epoch 4/20\n",
      "720/720 [==============================] - 0s 204us/sample - loss: 0.5216 - accuracy: 0.8056 - val_loss: 0.5392 - val_accuracy: 0.7125\n",
      "Epoch 5/20\n",
      "720/720 [==============================] - 0s 206us/sample - loss: 0.3900 - accuracy: 0.8986 - val_loss: 0.4182 - val_accuracy: 0.8625\n",
      "Epoch 6/20\n",
      "720/720 [==============================] - 0s 195us/sample - loss: 0.2742 - accuracy: 0.9361 - val_loss: 0.4326 - val_accuracy: 0.8250\n",
      "Epoch 7/20\n",
      "720/720 [==============================] - 0s 197us/sample - loss: 0.2108 - accuracy: 0.9417 - val_loss: 0.3815 - val_accuracy: 0.8250\n",
      "Epoch 8/20\n",
      "720/720 [==============================] - 0s 197us/sample - loss: 0.1510 - accuracy: 0.9708 - val_loss: 0.3501 - val_accuracy: 0.8500\n",
      "Epoch 9/20\n",
      "720/720 [==============================] - 0s 194us/sample - loss: 0.1237 - accuracy: 0.9722 - val_loss: 0.3765 - val_accuracy: 0.8125\n",
      "Epoch 10/20\n",
      "720/720 [==============================] - 0s 195us/sample - loss: 0.0957 - accuracy: 0.9819 - val_loss: 0.4832 - val_accuracy: 0.7875\n",
      "Epoch 11/20\n",
      "720/720 [==============================] - 0s 206us/sample - loss: 0.0746 - accuracy: 0.9875 - val_loss: 0.3954 - val_accuracy: 0.8250\n",
      "Epoch 12/20\n",
      "720/720 [==============================] - 0s 197us/sample - loss: 0.0624 - accuracy: 0.9875 - val_loss: 0.4739 - val_accuracy: 0.7750\n",
      "Epoch 13/20\n",
      "720/720 [==============================] - 0s 201us/sample - loss: 0.0535 - accuracy: 0.9903 - val_loss: 0.4988 - val_accuracy: 0.7875\n",
      "Epoch 14/20\n",
      "720/720 [==============================] - 0s 198us/sample - loss: 0.0458 - accuracy: 0.9903 - val_loss: 0.4485 - val_accuracy: 0.7875\n",
      "Epoch 15/20\n",
      "720/720 [==============================] - 0s 197us/sample - loss: 0.0393 - accuracy: 0.9903 - val_loss: 0.5318 - val_accuracy: 0.7625\n",
      "Epoch 16/20\n",
      "720/720 [==============================] - 0s 197us/sample - loss: 0.0349 - accuracy: 0.9958 - val_loss: 0.4938 - val_accuracy: 0.7875\n",
      "Epoch 17/20\n",
      "720/720 [==============================] - 0s 204us/sample - loss: 0.0329 - accuracy: 0.9931 - val_loss: 0.4961 - val_accuracy: 0.8125\n",
      "Epoch 18/20\n",
      "720/720 [==============================] - 0s 213us/sample - loss: 0.0287 - accuracy: 0.9931 - val_loss: 0.5145 - val_accuracy: 0.7875\n",
      "Epoch 19/20\n",
      "720/720 [==============================] - 0s 195us/sample - loss: 0.0270 - accuracy: 0.9944 - val_loss: 0.5553 - val_accuracy: 0.7875\n",
      "Epoch 20/20\n",
      "720/720 [==============================] - 0s 195us/sample - loss: 0.0243 - accuracy: 0.9972 - val_loss: 0.5679 - val_accuracy: 0.7750\n"
     ]
    }
   ],
   "source": [
    "## Algo_3 = ANN\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 100,activation = 'sigmoid',input_shape = (X_train.shape[1],)))\n",
    "\n",
    "classifier.add(Dense(units = 100,activation = 'sigmoid'))\n",
    "\n",
    "classifier.add(Dense(units = 1,activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "classifier.compile(loss= 'binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs= 20,validation_split = 0.1)\n",
    "\n",
    "y_pred_3 = classifier.predict(X_test)\n",
    "\n",
    "y_pred_3 = [1 if i>0.5 else 0 for i in y_pred_3 ]\n",
    "\n",
    "cm_3 = confusion_matrix(y_test,y_pred_3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.835\n",
      "Precision Score : 0.8240740740740741\n",
      "Recall Score : 0.8640776699029126\n",
      "F1 Score : 0.8436018957345971\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_3)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_3)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_3)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
